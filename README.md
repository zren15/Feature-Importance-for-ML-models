# The Five Methods to Estimate Feature Importance for ML models
- Spearman's Rank Correlation 
- Principle component analysis (PCA) 
- SHAP Importance 
- Drop Column Importance 
- Permutation Importance

The feature importance describes which features are relevant. It can help with a better understanding of the solved problem and sometimes lead to model improvement by utilizing feature selection. 

In this repo, I present 5 ways (with code) to compute feature importance for the Random Forest algorithm in Python, display importances and compare strategies by visualization and implemented Automatic feature selection algorithm.

Finally, I discuss Variance in Feature Importances that give a deeper understanding of the generated scores in the [jupyter notebook](https://github.com/zren15/Feature-Importance/blob/main/featimp.ipynb).
